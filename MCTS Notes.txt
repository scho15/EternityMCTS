Implemented with tree policy of sampling if epsilon < state visit count and greedy max if epsilon is small
state visit counts will need to be big (1000) before epsilon comes easily into play [e = 1000/(1000+svc)]
Tried average and maximum values as alternatives for "value" but decided that as "values" are meant to represent the most accurate final value, it was better using maximum rather than average
This is an "unusual" implementation for MCTS but hoping it works!!

Points to Try:
- Longer sampling times vs more episodes
- Smaller epsilons
- Terminal values fully solved for trees > 96 or 100 [should help a lot]
- Quicker algorithm - using matching tile not full tile set
- Q table reduction probably through using terminal values
- Need to determine how triple pattern tiles are dealt with (have 2 rotation positions) [tile alignment needs work]

Notes
- 5 10K sample runs took 22500s (6 hours) 42350s for 2 x 50K
- 100K is 237s (4 mins) per steps - likely 10-12 hrs
- With 50K can see about 30 ahead at some points - useful for avoiding challenging areas (but still hard to see past hint or centre tiles)
- 100K looks to improve this to 35 but again blocks at 35, 45, 119 etc so backtrack is almost certainly helpful
- 10K lengths: 127, 142, 170, 143, 143
- 50K lengths: 119, 166